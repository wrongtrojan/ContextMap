import os
import json
import yaml
import logging
from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection, utility

# 1. æ—¥å¿—é…ç½®
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("MilvusIngestor")

class MilvusIngestor:
    def __init__(self, force_reset=False):
        # --- è·¯å¾„ä¿®æ­£é€»è¾‘ ---
        # self.script_dir æ˜¯ ~/AcademicAgent-Suite/data_layer
        self.script_dir = os.path.dirname(os.path.abspath(__file__))
        # self.root_dir æ˜¯ ~/AcademicAgent-Suite
        self.root_dir = os.path.dirname(self.script_dir)
        # é…ç½®æ–‡ä»¶åœ¨ ~/AcademicAgent-Suite/configs
        config_dir = os.path.join(self.root_dir, "configs")
        
        logger.info(f"æ­£åœ¨ä»ä»¥ä¸‹ç›®å½•åŠ è½½é…ç½®: {config_dir}")
        
        # åŠ è½½åŒé…ç½®
        try:
            with open(os.path.join(config_dir, "model_config.yaml"), 'r', encoding='utf-8') as f:
                self.model_cfg = yaml.safe_load(f)
            with open(os.path.join(config_dir, "milvus_config.yaml"), 'r', encoding='utf-8') as f:
                self.db_cfg = yaml.safe_load(f)
        except FileNotFoundError as e:
            logger.error(f"é…ç½®æ–‡ä»¶ç¼ºå¤±ï¼Œè¯·æ£€æŸ¥è·¯å¾„: {e}")
            raise

        # 2. è¿æ¥ Milvus
        conn = self.db_cfg['connection']
        connections.connect("default", host=conn['host'], port=conn['port'])
        self.col_name = self.db_cfg['collection']['name']
        
        # å¼ºåˆ¶é‡ç½®é€»è¾‘
        if force_reset and utility.has_collection(self.col_name):
            utility.drop_collection(self.col_name)
            logger.warning(f"âš ï¸ å·²é‡ç½®é›†åˆ: {self.col_name}")

        self._setup_collection()

    def _setup_collection(self):
        """å®šä¹‰ Schema"""
        if utility.has_collection(self.col_name):
            self.collection = Collection(self.col_name)
            self.collection.load()
            return

        s = self.db_cfg['schema']
        c = self.db_cfg['collection']

        fields = [
            FieldSchema(name=s['pk'], dtype=DataType.INT64, is_primary=True, auto_id=True),
            FieldSchema(name="doc_name", dtype=DataType.VARCHAR, max_length=500),
            FieldSchema(name="source_type", dtype=DataType.VARCHAR, max_length=50), 
            FieldSchema(name="content_ref", dtype=DataType.VARCHAR, max_length=1000),
            FieldSchema(name=s['vec'], dtype=DataType.FLOAT_VECTOR, dim=c['dim'])
        ]
        
        schema = CollectionSchema(fields, "Academic Multimodal Index")
        self.collection = Collection(self.col_name, schema)

        index_params = {
            "metric_type": c['metric_type'],
            "index_type": c['index_type'],
            "params": {"nlist": c['nlist']}
        }
        self.collection.create_index(field_name=s['vec'], index_params=index_params)
        self.collection.load()
        logger.info(f"âœ… Milvus é›†åˆ {self.col_name} åˆå§‹åŒ–æˆåŠŸ")

    def _is_doc_ingested(self, doc_name):
        res = self.collection.query(expr=f'doc_name == "{doc_name}"', output_fields=["id"], limit=1)
        return len(res) > 0

    def run_ingestion(self):
        """åŒæ­¥ multimodal_features.json åˆ° Milvus"""
        # è¿™é‡Œçš„ processed_storage å·²ç»åœ¨ model_config.yaml é‡Œå®šä¹‰ä¸ºç»å¯¹è·¯å¾„äº†
        processed_root = os.path.join(self.model_cfg['paths']['processed_storage'], "magic-pdf")
        
        if not os.path.exists(processed_root):
            logger.error(f"æœªæ‰¾åˆ° magic-pdf å¤„ç†ç›®å½•: {processed_root}")
            return

        total_count = 0
        for doc_name in os.listdir(processed_root):
            doc_dir = os.path.join(processed_root, doc_name)
            feature_path = os.path.join(doc_dir, "multimodal_features.json")
            
            if not os.path.exists(feature_path): continue
            if self._is_doc_ingested(doc_name):
                logger.info(f"â­ï¸ è·³è¿‡å·²å…¥åº“æ–‡æ¡£: {doc_name}")
                continue

            logger.info(f"ğŸš€ æ­£åœ¨åŒæ­¥: {doc_name}")
            with open(feature_path, 'r', encoding='utf-8') as f:
                data = json.load(f)

            names, types, refs, vecs = [], [], [], []

            # æå–å›¾ç‰‡
            for img_name, img_data in data.get("images", {}).items():
                names.append(doc_name)
                types.append("image")
                refs.append(img_name)
                vecs.append(img_data if isinstance(img_data, list) else img_data.get("embedding"))

            # æå–æ–‡æœ¬
            for chunk in data.get("text_chunks", []):
                names.append(doc_name)
                types.append("text")
                refs.append(chunk.get("text_slice", "text_chunk"))
                vecs.append(chunk["embedding"])

            if names:
                self.collection.insert([names, types, refs, vecs])
                total_count += len(names)
                logger.info(f"ğŸ“ˆ æ’å…¥æ•°æ®: {len(names)} æ¡")

        self.collection.flush()
        logger.info(f"âœ¨ åŒæ­¥ç»“æŸï¼Œæ€»è®¡å…¥åº“ {total_count} æ¡å‘é‡ã€‚")

if __name__ == "__main__":
    # ç¬¬ä¸€æ¬¡è¿è¡Œå»ºè®®ä¸º True
    ingestor = MilvusIngestor(force_reset=False)
    ingestor.run_ingestion()